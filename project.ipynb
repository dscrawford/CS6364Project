{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from os.path import exists\n",
    "from os import mkdir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# File\n",
    "# dir = '../input/riiid-test-answer-prediction/'\n",
    "dir = './'\n",
    "FEATURE_FOLDER_PATH = dir + 'riiid_features/'\n",
    "\n",
    "# Hyper parameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\n",
    "# Read large datasets: https://www.kaggle.com/rohanrao/tutorial-on-reading-large-datasets\n",
    "train_dtypes = {\n",
    "    \"row_id\": \"int64\",\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"boolean\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    \"user_answer\": \"int8\",\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\",\n",
    "    \"prior_question_had_explanation\": \"boolean\"\n",
    "}\n",
    "\n",
    "# why we removed columns:\n",
    "#   row_id: redundant\n",
    "#   task_container_id: tells you what container this question is in\n",
    "#       the max container size is 5 so not really significant\n",
    "#   user_answer: doesnt really affect if the answer is correct\n",
    "#   prior_question_had_explanation: majority of learning (we assume) will be done from lectures, not answer explanations\n",
    "#\n",
    "\n",
    "req_cols = ['timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly', 'prior_question_elapsed_time',\n",
    "            'prior_question_had_explanation']\n",
    "\n",
    "# function to convert the milliseconds to seconds at load time\n",
    "# messes with the dtypes above and doesn't really save time so it is commented (see converters)\n",
    "def mil_to_sec(val):\n",
    "    if val == '':\n",
    "        return np.NaN\n",
    "    return round(int(val)/1000)\n",
    "\n",
    "train_columns = pd.read_csv(dir + 'train.csv', usecols=req_cols, nrows=1).columns\n",
    "t_index = {col: i for (i, col) in enumerate(train_columns)}\n",
    "train = pd.read_csv(dir + 'train.csv', usecols=req_cols, dtype=train_dtypes,\n",
    "                       # converters={'timestamp': mil_to_sec,\n",
    "                       #             'prior_question_elapsed_time': mil_to_sec},\n",
    "                       nrows=10000000).to_numpy()\n",
    "# the following lines are kinda cheating since we don't actually have all the data at once\n",
    "# train_df = raw_df[raw_df['content_type_id'] == 0]\n",
    "# lecture_events_df = raw_df[raw_df['content_type_id'] == 1]\n",
    "\n",
    "questions_df = pd.read_csv(dir + 'questions.csv')\n",
    "lectures_df = pd.read_csv(dir + 'lectures.csv')\n",
    "example_test_df = pd.read_csv(dir + 'example_test.csv')\n",
    "\n",
    "# train_df = train_df.drop(['content_id', 'content_type_id'], axis=1) # TODO: replace\n",
    "\n",
    "# we need a way to dummify the user id\n",
    "# pd.get_dummies(train_df, columns=['user_id']) # DO NOT TRY THIS IT WILL OVERLOAD RAM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([], shape=(0, 7), dtype=object)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_col = train[:,t_index['prior_question_elapsed_time']]\n",
    "train[prior_col == np.nan]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def jagged_to_fixed_matrix(x, n , fill_value):\n",
    "    a = np.full((len(x), n), fill_value)\n",
    "    for i,xi in enumerate(x):\n",
    "        a[i][0:min(n,len(xi))] = np.array(xi)[0:min(n, len(xi))]\n",
    "    return a\n",
    "\n",
    "def create_batch_iter(n, skip):\n",
    "    a = list(range(0, n, skip)) + [len(train)]\n",
    "    return [(a[i], a[i + 1]) for i in range(len(a) - 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class StudentKnowledge:\n",
    "    def __init__(self, num_tags, max_tags=30, question_avg_default=0.67):\n",
    "        self.lectures = []\n",
    "        self.lecture_timestamp = []\n",
    "        self.questions = []\n",
    "        self.question_timestamp = []\n",
    "        self.num_tags = num_tags\n",
    "\n",
    "        self.question_avg_default = question_avg_default\n",
    "        self.max_tags = max_tags\n",
    "\n",
    "    def add_lecture(self, lecture_tag, lecture_timestamp):\n",
    "        self.lectures.append(lecture_tag)\n",
    "        self.lecture_timestamp.append(lecture_timestamp)\n",
    "\n",
    "    def add_question(self, question_answered_right, question_timestamp):\n",
    "        self.questions.append(question_answered_right)\n",
    "        self.question_timestamp.append(question_timestamp)\n",
    "\n",
    "    def get_features(self, row):\n",
    "        timestamp = row[t_index['timestamp']]\n",
    "        prior_question_elapsed = row[t_index['prior_question_elapsed_time']]\n",
    "        prior_question_explain = row[t_index['prior_question_had_explanation']]\n",
    "        # Lecture Tag Indices\n",
    "        before_ts_lecture = [lt > timestamp for lt in self.lecture_timestamp]\n",
    "        valid_lectures = [self.lectures[i] for i in range(len(self.lectures)) if before_ts_lecture[i]]\n",
    "\n",
    "        # Additional Features\n",
    "        before_ts_question = [qt > timestamp for qt in self.question_timestamp]\n",
    "        num_questions_answered = sum(before_ts_question)\n",
    "        if num_questions_answered == 0:\n",
    "            question_avg = self.question_avg_default\n",
    "        else:\n",
    "            question_avg = sum([self.questions[i] for i in range(len(self.questions)) if before_ts_question[i]]) / num_questions_answered\n",
    "        prior_question_elapsed = 0 if str(prior_question_elapsed) == 'nan' else prior_question_elapsed\n",
    "        prior_question_explain = False if str(prior_question_explain) == '<NA>' else prior_question_explain\n",
    "\n",
    "        return valid_lectures, [question_avg, prior_question_elapsed, prior_question_explain]\n",
    "\n",
    "\n",
    "\n",
    "class StudentDataset:\n",
    "    def __init__(self, lectures, questions, train_columns, tags_len=30):\n",
    "        self.t_index = {col: i for i, col in enumerate(train_columns)}\n",
    "\n",
    "        self.students = {}\n",
    "        self.lecture_tags = {row['lecture_id']: row['tag'] for _, row in lectures.iterrows()}\n",
    "        self.question_tags = {row['question_id']: [int(x) for x in str(row['tags']).split() if x != 'nan'] \\\n",
    "                              for _, row in questions.iterrows()}\n",
    "\n",
    "        a = questions['tags'].apply(lambda r: [int(x) for x in str(r).split() if x != 'nan']).to_numpy()\n",
    "        self.num_tags = len(np.unique([x for b in a for x in b]))\n",
    "        self.tags_len = tags_len\n",
    "\n",
    "    def read(self, row):\n",
    "        student_id = row[self.t_index['user_id']]\n",
    "        content_type_id = row[self.t_index['content_type_id']]\n",
    "        content_id = row[self.t_index['content_id']]\n",
    "        timestamp = row[self.t_index['timestamp']]\n",
    "        answered_right = row[self.t_index['answered_correctly']]\n",
    "\n",
    "        self.read_info(student_id, content_type_id, content_id, timestamp, answered_right)\n",
    "\n",
    "    def read_info(self, student_id, content_type_id, content_id, timestamp, answered_right):\n",
    "        if student_id not in self.students:\n",
    "            self.students[student_id] = StudentKnowledge(self.num_tags)\n",
    "        if content_type_id == 0:\n",
    "            self.students[student_id].add_question(answered_right, timestamp)\n",
    "        else:\n",
    "            self.students[student_id].add_lecture(self.lecture_tags[content_id], timestamp)\n",
    "\n",
    "    # Must receive question rows, lectures not valid\n",
    "    def get_features(self, rows):\n",
    "        user_ids = rows[:,self.t_index['user_id']]\n",
    "        question_ids = rows[:, self.t_index['content_id']]\n",
    "\n",
    "        question_tags = [self.question_tags[question_id] for question_id in question_ids]\n",
    "        question_tags = jagged_to_fixed_matrix(question_tags, self.tags_len, self.num_tags)\n",
    "\n",
    "        student_tags, additional_features = zip(\n",
    "            *[self.students[user_id].get_features(rows[i]) for i, user_id in enumerate(user_ids)]\n",
    "        )\n",
    "        student_tags = jagged_to_fixed_matrix(list(student_tags), self.tags_len, self.num_tags)\n",
    "        return question_tags, student_tags, list(additional_features)\n",
    "\n",
    "class Network(nn.Module):\n",
    "  def __init__(self, num_embeddings, extra_input_dim, hidden_1, hidden_2, embedding_dim=20):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n",
    "\n",
    "    self.layers = nn.ModuleList([\n",
    "      nn.Linear(extra_input_dim + 2 * embedding_dim, hidden_1),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_1, hidden_2),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_2, 1)\n",
    "    ])\n",
    "\n",
    "  def forward(self, student_indices, question_indices, features):\n",
    "    y1 = torch.cat(self.embedding(student_indices), dim=1)\n",
    "    y2 = torch.cat(self.embedding(question_indices), dim=1)\n",
    "\n",
    "    y = torch.cat((y1, y2, features), dim=1)\n",
    "    for layer in self.layers:\n",
    "        y = layer(y)\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000000/10000000 [00:11<00:00, 875314.10it/s]\n"
     ]
    }
   ],
   "source": [
    "student_dataset = StudentDataset(lectures_df, questions_df, train_columns)\n",
    "\n",
    "for row in tqdm(train):\n",
    "    student_dataset.read(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Select only the questions\n",
    "train = train[train[:,t_index['content_type_id']]==0][0:10000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# if not exists(FEATURE_FOLDER_PATH):\n",
    "#     mkdir(FEATURE_FOLDER_PATH)\n",
    "#     chunksize = 10000\n",
    "#     for i,j in tqdm(create_batch_iter(len(train), chunksize)):\n",
    "#         question_tags, student_tags, f = student_dataset.get_features(train[i:j])\n",
    "#         labels = train[i:j]['']\n",
    "#         pd.DataFrame(question_tags).to_csv(FEATURE_FOLDER_PATH + 'questions.csv', mode='a', index=False)\n",
    "#         pd.DataFrame(student_tags).to_csv(FEATURE_FOLDER_PATH + 'student.csv', mode='a', index=False)\n",
    "#         pd.DataFrame(f).to_csv(FEATURE_FOLDER_PATH + 'extra.csv', mode='a', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Compute input sizes\n",
    "_, _, f = student_dataset.get_features(np.array([train[0]]))\n",
    "extra_input_dim = len(f[0])\n",
    "num_embeddings = student_dataset.num_tags + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 32.91097988204956, Train Accuracy: 56.68%: 100%|██████████| 313/313 [00:06<00:00, 48.37it/s] \n",
      "Avg Loss: 15.887437721252441, Train Accuracy: 56.96%: 100%|██████████| 313/313 [00:06<00:00, 50.38it/s]\n",
      "Avg Loss: 16.589845665359498, Train Accuracy: 57.19%: 100%|██████████| 313/313 [00:06<00:00, 49.54it/s]\n",
      "Avg Loss: 11.129831821918488, Train Accuracy: 56.73%: 100%|██████████| 313/313 [00:06<00:00, 49.52it/s]\n",
      "Avg Loss: 9.877737319374084, Train Accuracy: 56.81%: 100%|██████████| 313/313 [00:06<00:00, 50.12it/s] \n",
      "Avg Loss: 8.285740426445008, Train Accuracy: 56.62%: 100%|██████████| 313/313 [00:06<00:00, 48.89it/s] \n",
      "Avg Loss: 6.825373198986053, Train Accuracy: 56.39%: 100%|██████████| 313/313 [00:06<00:00, 51.86it/s] \n",
      "Avg Loss: 6.252027510356903, Train Accuracy: 56.42%: 100%|██████████| 313/313 [00:06<00:00, 50.31it/s] \n",
      "Avg Loss: 7.602202873420715, Train Accuracy: 57.05%: 100%|██████████| 313/313 [00:06<00:00, 49.21it/s] \n",
      "Avg Loss: 7.484163282926266, Train Accuracy: 58.15%:  42%|████▏     | 130/313 [00:02<00:03, 47.79it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-34-f1e63586f83a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtq\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m         \u001B[0mquestion_tags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstudent_tags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstudent_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m         \u001B[0mquestion_tags\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion_tags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0mstudent_tags\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstudent_tags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-25-f26307395892>\u001B[0m in \u001B[0;36mget_features\u001B[0;34m(self, rows)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m         student_tags, additional_features = zip(\n\u001B[0;32m---> 81\u001B[0;31m             \u001B[0;34m*\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstudents\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrows\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_id\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     82\u001B[0m         )\n\u001B[1;32m     83\u001B[0m         \u001B[0mstudent_tags\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjagged_to_fixed_matrix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstudent_tags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtags_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_tags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-25-f26307395892>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m         student_tags, additional_features = zip(\n\u001B[0;32m---> 81\u001B[0;31m             \u001B[0;34m*\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstudents\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrows\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_id\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     82\u001B[0m         )\n\u001B[1;32m     83\u001B[0m         \u001B[0mstudent_tags\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjagged_to_fixed_matrix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstudent_tags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtags_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_tags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-25-f26307395892>\u001B[0m in \u001B[0;36mget_features\u001B[0;34m(self, row)\u001B[0m\n\u001B[1;32m     32\u001B[0m             \u001B[0mquestion_avg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquestion_avg_default\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m             \u001B[0mquestion_avg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquestions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquestions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mbefore_ts_question\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mnum_questions_answered\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m         \u001B[0mprior_question_elapsed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprior_question_elapsed\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'nan'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mprior_question_elapsed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0mprior_question_explain\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprior_question_explain\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'<NA>'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mprior_question_explain\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-25-f26307395892>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     32\u001B[0m             \u001B[0mquestion_avg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquestion_avg_default\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m             \u001B[0mquestion_avg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquestions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquestions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mbefore_ts_question\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mnum_questions_answered\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m         \u001B[0mprior_question_elapsed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprior_question_elapsed\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'nan'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mprior_question_elapsed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0mprior_question_explain\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprior_question_explain\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'<NA>'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mprior_question_explain\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Network(student_dataset.num_tags + 1, extra_input_dim, 64, 32, embedding_dim=5).to(device)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "for epoch in range(20):\n",
    "    tq = tqdm(create_batch_iter(len(train), BATCH_SIZE))\n",
    "\n",
    "    # Average Loss Variables\n",
    "    total_loss = 0\n",
    "    current_len = 0\n",
    "    total_correct = 0\n",
    "    total_len = 0\n",
    "\n",
    "    for i,j in tq:\n",
    "        question_tags, student_tags, f = student_dataset.get_features(train[i:j])\n",
    "        question_tags = torch.tensor(question_tags).long().to(device)\n",
    "        student_tags = torch.tensor(student_tags).long().to(device)\n",
    "        n = len(f)\n",
    "\n",
    "        f = torch.tensor(f).view(n, len(f[0])).float().to(device)\n",
    "\n",
    "        labels = torch.tensor(\n",
    "            train[i:j, t_index['answered_correctly']].astype(np.bool)\n",
    "        ).view(n, 1).float().to(device)\n",
    "\n",
    "        predictions = model(question_tags, student_tags, f)\n",
    "\n",
    "        loss = loss_func(predictions, labels.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_len += n\n",
    "        total_loss += loss.item() * n\n",
    "\n",
    "        total_correct += np.sum(np.round(torch.sigmoid(predictions).cpu().view(n).detach().numpy()) == labels.cpu().view(n).detach().numpy())\n",
    "        tq.set_description('Avg Loss: ' + str(total_loss / current_len) + ', Train Accuracy: '  + \\\n",
    "                           str(np.round(total_correct / current_len * 100, 2)) + '%')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}