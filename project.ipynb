{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# dir = '../input/riiid-test-answer-prediction/'\n",
    "dir = './'\n",
    "# Read large datasets: https://www.kaggle.com/rohanrao/tutorial-on-reading-large-datasets\n",
    "train_dtypes = {\n",
    "    \"row_id\": \"int64\",\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"boolean\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    \"user_answer\": \"int8\",\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\",\n",
    "    \"prior_question_had_explanation\": \"boolean\"\n",
    "}\n",
    "\n",
    "# why we removed columns:\n",
    "#   row_id: redundant\n",
    "#   task_container_id: tells you what container this question is in\n",
    "#       the max container size is 5 so not really significant\n",
    "#   user_answer: doesnt really affect if the answer is correct\n",
    "#   prior_question_had_explanation: majority of learning (we assume) will be done from lectures, not answer explanations\n",
    "#\n",
    "\n",
    "req_cols = ['timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly']\n",
    "            # 'prior_question_elapsed_time']\n",
    "\n",
    "# function to convert the milliseconds to seconds at load time\n",
    "# messes with the dtypes above and doesn't really save time so it is commented (see converters)\n",
    "def mil_to_sec(val):\n",
    "    if val == '':\n",
    "        return np.NaN\n",
    "    return round(int(val)/1000)\n",
    "\n",
    "train_columns = pd.read_csv(dir + 'train.csv', usecols=req_cols, nrows=1).columns\n",
    "train = pd.read_csv(dir + 'train.csv', usecols=req_cols, dtype=train_dtypes,\n",
    "                       # converters={'timestamp': mil_to_sec,\n",
    "                       #             'prior_question_elapsed_time': mil_to_sec},\n",
    "                       nrows=1000).to_numpy()\n",
    "# the following lines are kinda cheating since we don't actually have all the data at once\n",
    "# train_df = raw_df[raw_df['content_type_id'] == 0]\n",
    "# lecture_events_df = raw_df[raw_df['content_type_id'] == 1]\n",
    "\n",
    "questions_df = pd.read_csv(dir + 'questions.csv')\n",
    "lectures_df = pd.read_csv(dir + 'lectures.csv')\n",
    "example_test_df = pd.read_csv(dir + 'example_test.csv')\n",
    "\n",
    "# train_df = train_df.drop(['content_id', 'content_type_id'], axis=1) # TODO: replace\n",
    "\n",
    "# we need a way to dummify the user id\n",
    "# pd.get_dummies(train_df, columns=['user_id']) # DO NOT TRY THIS IT WILL OVERLOAD RAM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class StudentKnowledge:\n",
    "    def __init__(self, num_tags):\n",
    "        self.lectures = []\n",
    "        self.lecture_timestamp = []\n",
    "        self.questions = []\n",
    "        self.question_timestamp = []\n",
    "        self.num_tags = num_tags\n",
    "\n",
    "    def add_lecture(self, lecture_tag, lecture_timestamp):\n",
    "        self.lectures.append(lecture_tag)\n",
    "        self.lecture_timestamp.append(lecture_timestamp)\n",
    "\n",
    "    def add_question(self, question_answered_right, question_timestamp):\n",
    "        self.questions.append(question_answered_right)\n",
    "        self.question_timestamp.append(question_timestamp)\n",
    "\n",
    "    def get_features(self, timestamp):\n",
    "        features = np.zeros(self.num_tags + 1)\n",
    "        before_ts_lecture = [lt > timestamp for lt in self.lecture_timestamp]\n",
    "        valid_tags_lecture = [self.lectures[i] for i in range(len(self.lectures)) if before_ts_lecture[i]]\n",
    "        before_ts_question = [qt > timestamp for qt in self.question_timestamp]\n",
    "        question_avg = sum([self.questions[i] for i in range(len(self.questions)) if before_ts_question[i]]) / sum(before_ts_question)\n",
    "        features[valid_tags_lecture] = 1\n",
    "        features[-1] = question_avg\n",
    "        return features\n",
    "\n",
    "class StudentDataset:\n",
    "    def __init__(self, lectures, questions, train_columns):\n",
    "        self.students = {}\n",
    "        self.lecture_tags = {row['lecture_id']: row['tag'] for _, row in lectures.iterrows()}\n",
    "        self.question_tags = {row['question_id']: [int(x) for x in str(row['tags']).split() if x != 'nan'] for _, row in questions.iterrows()}\n",
    "        self.t_index = {col: i for i, col in enumerate(train_columns)}\n",
    "\n",
    "        a = questions['tags'].apply(lambda r: [int(x) for x in str(r).split() if x != 'nan']).to_numpy()\n",
    "        self.num_tags = len(np.unique([x for b in a for x in b]))\n",
    "\n",
    "    def read(self, row):\n",
    "        student_id = row[self.t_index['user_id']]\n",
    "        content_type_id = row[self.t_index['content_type_id']]\n",
    "        content_id = row[self.t_index['content_id']]\n",
    "        timestamp = row[self.t_index['timestamp']]\n",
    "        answered_right = row[self.t_index['answered_correctly']]\n",
    "        self.read_info(student_id, content_type_id, content_id, timestamp, answered_right)\n",
    "\n",
    "    def read_info(self, student_id, content_type_id, content_id, timestamp, answered_right):\n",
    "        if student_id not in self.students:\n",
    "            self.students[student_id] = StudentKnowledge(self.num_tags)\n",
    "        if content_type_id == 0:\n",
    "            self.students[student_id].add_question(answered_right, timestamp)\n",
    "        else:\n",
    "            self.students[student_id].add_lecture(self.lecture_tags[content_id], timestamp)\n",
    "\n",
    "    # Must receive a question vector, lectures not valid\n",
    "    def get_features(self, rows):\n",
    "        user_ids = rows[:,self.t_index['user_id']]\n",
    "        timestamps = rows[:,self.t_index['timestamp']]\n",
    "        question_ids = rows[:, self.t_index['content_id']]\n",
    "\n",
    "        question_features = np.zeros((len(rows), self.num_tags))\n",
    "        for i, question_id in enumerate(question_ids):\n",
    "            question_features[i,self.question_tags[question_id]] = 1\n",
    "\n",
    "        student_features = np.array([self.students[user_id].get_features(timestamp)\n",
    "                                     for user_id, timestamp in zip(user_ids, timestamps)])\n",
    "\n",
    "        return np.hstack([question_features, student_features])\n",
    "\n",
    "student_dataset = StudentDataset(lectures_df, questions_df, train_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 499619.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(train):\n",
    "    student_dataset.read(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 115 5692 False 1]\n",
      " [56943 115 5716 False 1]\n",
      " [118363 115 128 False 1]\n",
      " [131167 115 7860 False 1]\n",
      " [137965 115 7922 False 1]\n",
      " [157063 115 156 False 1]\n",
      " [176092 115 51 False 1]\n",
      " [194190 115 50 False 1]\n",
      " [212463 115 7896 False 1]\n",
      " [230983 115 7863 False 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.69565217],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.68888889],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.68181818],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.64102564],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.63157895],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.62162162]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example features with train\n",
    "print(train[0:10])\n",
    "student_dataset.get_features(train[0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "  def __init__(self, inputs, hidden, lr=0.001):\n",
    "    super().__init__()\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Linear(inputs, hidden),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden, 1),\n",
    "    )\n",
    "    self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.main(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.47721028327941895: 100%|██████████| 982/982 [00:01<00:00, 646.16it/s]\n",
      "0.5117090940475464: 100%|██████████| 982/982 [00:01<00:00, 694.01it/s] \n",
      "0.5589438676834106: 100%|██████████| 982/982 [00:01<00:00, 691.92it/s] \n",
      "0.6039080619812012: 100%|██████████| 982/982 [00:01<00:00, 714.20it/s] \n",
      "0.6484382748603821: 100%|██████████| 982/982 [00:01<00:00, 710.09it/s] \n",
      "0.675808846950531: 100%|██████████| 982/982 [00:01<00:00, 686.56it/s]   \n",
      "0.71211838722229: 100%|██████████| 982/982 [00:01<00:00, 673.43it/s]    \n",
      "0.754368782043457: 100%|██████████| 982/982 [00:01<00:00, 646.40it/s]   \n",
      "0.7781763672828674: 100%|██████████| 982/982 [00:01<00:00, 652.69it/s]  \n",
      "0.801904022693634: 100%|██████████| 982/982 [00:01<00:00, 652.96it/s]   \n",
      "0.8250249028205872: 100%|██████████| 982/982 [00:01<00:00, 656.88it/s]  \n",
      "0.8431645035743713: 100%|██████████| 982/982 [00:01<00:00, 577.36it/s]   \n",
      "0.8558878302574158: 100%|██████████| 982/982 [00:01<00:00, 657.00it/s]   \n",
      "0.8667155504226685: 100%|██████████| 982/982 [00:01<00:00, 711.46it/s]   \n",
      "0.8806516528129578: 100%|██████████| 982/982 [00:01<00:00, 717.19it/s]   \n",
      "0.8886072039604187: 100%|██████████| 982/982 [00:01<00:00, 708.89it/s]   \n",
      "0.8921254873275757: 100%|██████████| 982/982 [00:01<00:00, 707.64it/s]    \n",
      "0.9092730283737183: 100%|██████████| 982/982 [00:01<00:00, 718.33it/s]    \n",
      "0.900749146938324: 100%|██████████| 982/982 [00:01<00:00, 704.94it/s]     \n",
      "0.9233396053314209: 100%|██████████| 982/982 [00:01<00:00, 706.36it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: 0.6595275169295352\n",
      "mean loss: 0.6426682004708865\n",
      "mean loss: 0.6291753450473069\n",
      "mean loss: 0.6133536751364982\n",
      "mean loss: 0.5950161170578597\n",
      "mean loss: 0.5767507815767694\n",
      "mean loss: 0.558864320958386\n",
      "mean loss: 0.5422472487528127\n",
      "mean loss: 0.5268002794804184\n",
      "mean loss: 0.5129485195836948\n",
      "mean loss: 0.49938805383335383\n",
      "mean loss: 0.4870936342406371\n",
      "mean loss: 0.4750490730202394\n",
      "mean loss: 0.4639553778206947\n",
      "mean loss: 0.45314748302022134\n",
      "mean loss: 0.44310402308372693\n",
      "mean loss: 0.43323565440822187\n",
      "mean loss: 0.4242707047260686\n",
      "mean loss: 0.41552238765069466\n",
      "mean loss: 0.40741920772696494\n"
     ]
    }
   ],
   "source": [
    "train = train[train[:,3]==0]\n",
    "model = Network(len(student_dataset.get_features(train[0:10])[0]), 16)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "for epoch in range(20):\n",
    "    tq = tqdm(train)\n",
    "    losses = []\n",
    "    for row in tq:\n",
    "        prediction = model(torch.tensor(student_dataset.get_features(np.array([row[:-1]]))).float())\n",
    "        loss = loss_func(prediction, torch.tensor(row[-1]).view(1,1).float())\n",
    "        model.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "        tq.set_description(str(loss.item()))\n",
    "        losses += [loss.item()]\n",
    "    print('mean loss:', sum(losses)/len(losses))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8319755600814664\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_correct = 0\n",
    "    for row in train: # replace with test/val set\n",
    "        prediction = model(torch.tensor(student_dataset.get_features(np.array([row[:-1]]))).float())\n",
    "        total_correct += round(torch.sigmoid(prediction).item()) == row[-1]\n",
    "    print(total_correct/len(train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}