{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# dir = '../input/riiid-test-answer-prediction/'\n",
    "dir = './'\n",
    "# Read large datasets: https://www.kaggle.com/rohanrao/tutorial-on-reading-large-datasets\n",
    "train_dtypes = {\n",
    "    \"row_id\": \"int64\",\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"boolean\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    \"user_answer\": \"int8\",\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\",\n",
    "    \"prior_question_had_explanation\": \"boolean\"\n",
    "}\n",
    "\n",
    "# why we removed columns:\n",
    "#   row_id: redundant\n",
    "#   task_container_id: tells you what container this question is in\n",
    "#       the max container size is 5 so not really significant\n",
    "#   user_answer: doesnt really affect if the answer is correct\n",
    "#   prior_question_had_explanation: majority of learning (we assume) will be done from lectures, not answer explanations\n",
    "#\n",
    "\n",
    "req_cols = ['timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly']\n",
    "            # 'prior_question_elapsed_time']\n",
    "\n",
    "# function to convert the milliseconds to seconds at load time\n",
    "# messes with the dtypes above and doesn't really save time so it is commented (see converters)\n",
    "def mil_to_sec(val):\n",
    "    if val == '':\n",
    "        return np.NaN\n",
    "    return round(int(val)/1000)\n",
    "\n",
    "train_columns = pd.read_csv(dir + 'train.csv', usecols=req_cols, nrows=1).columns\n",
    "train = pd.read_csv(dir + 'train.csv', usecols=req_cols, dtype=train_dtypes,\n",
    "                       # converters={'timestamp': mil_to_sec,\n",
    "                       #             'prior_question_elapsed_time': mil_to_sec},\n",
    "                       nrows=1000).to_numpy()\n",
    "# the following lines are kinda cheating since we don't actually have all the data at once\n",
    "# train_df = raw_df[raw_df['content_type_id'] == 0]\n",
    "# lecture_events_df = raw_df[raw_df['content_type_id'] == 1]\n",
    "\n",
    "questions_df = pd.read_csv(dir + 'questions.csv')\n",
    "lectures_df = pd.read_csv(dir + 'lectures.csv')\n",
    "example_test_df = pd.read_csv(dir + 'example_test.csv')\n",
    "\n",
    "# train_df = train_df.drop(['content_id', 'content_type_id'], axis=1) # TODO: replace\n",
    "\n",
    "# we need a way to dummify the user id\n",
    "# pd.get_dummies(train_df, columns=['user_id']) # DO NOT TRY THIS IT WILL OVERLOAD RAM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "class StudentKnowledge:\n",
    "    def __init__(self, num_tags):\n",
    "        self.lectures = []\n",
    "        self.lecture_timestamp = []\n",
    "        self.questions = []\n",
    "        self.question_timestamp = []\n",
    "        self.num_tags = num_tags\n",
    "\n",
    "    def add_lecture(self, lecture_tag, lecture_timestamp):\n",
    "        self.lectures.append(lecture_tag)\n",
    "        self.lecture_timestamp.append(lecture_timestamp)\n",
    "\n",
    "    def add_question(self, question_answered_right, question_timestamp):\n",
    "        self.questions.append(question_answered_right)\n",
    "        self.question_timestamp.append(question_timestamp)\n",
    "\n",
    "    def get_features(self, timestamp):\n",
    "        features = np.zeros(self.num_tags + 1)\n",
    "        before_ts_lecture = [lt >= timestamp for lt in self.lecture_timestamp]\n",
    "        valid_tags_lecture = [self.lectures[i] for i in range(len(self.lectures)) if before_ts_lecture[i]]\n",
    "        before_ts_question = [qt >= timestamp for qt in self.question_timestamp]\n",
    "        question_avg = sum([self.questions[i] for i in range(len(self.questions)) if before_ts_question[i]]) / sum(before_ts_question)\n",
    "        features[valid_tags_lecture] = 1\n",
    "        features[-1] = question_avg\n",
    "        return features\n",
    "\n",
    "class StudentDataset:\n",
    "    def __init__(self, lectures, questions, train_columns):\n",
    "        self.students = {}\n",
    "        self.lecture_tags = {row['lecture_id']: row['tag'] for _, row in lectures.iterrows()}\n",
    "        self.question_tags = {row['question_id']: [int(x) for x in str(row['tags']).split() if x != 'nan'] for _, row in questions.iterrows()}\n",
    "        self.t_index = {col: i for i, col in enumerate(train_columns)}\n",
    "\n",
    "        a = questions['tags'].apply(lambda r: [int(x) for x in str(r).split() if x != 'nan']).to_numpy()\n",
    "        self.num_tags = len(np.unique([x for b in a for x in b]))\n",
    "\n",
    "    def read(self, row):\n",
    "        student_id = row[self.t_index['user_id']]\n",
    "        content_type_id = row[self.t_index['content_type_id']]\n",
    "        content_id = row[self.t_index['content_id']]\n",
    "        timestamp = row[self.t_index['timestamp']]\n",
    "        answered_right = row[self.t_index['answered_correctly']]\n",
    "        self.read_info(student_id, content_type_id, content_id, timestamp, answered_right)\n",
    "\n",
    "    def read_info(self, student_id, content_type_id, content_id, timestamp, answered_right):\n",
    "        if student_id not in self.students:\n",
    "            self.students[student_id] = StudentKnowledge(self.num_tags)\n",
    "        if content_type_id == 0:\n",
    "            self.students[student_id].add_question(answered_right, timestamp)\n",
    "        else:\n",
    "            self.students[student_id].add_lecture(self.lecture_tags[content_id], timestamp)\n",
    "\n",
    "    # Must receive a question vector, lectures not valid\n",
    "    def get_features(self, rows):\n",
    "        user_ids = rows[:,self.t_index['user_id']]\n",
    "        timestamps = rows[:,self.t_index['timestamp']]\n",
    "        question_ids = rows[:, self.t_index['content_id']]\n",
    "\n",
    "        question_features = np.zeros((len(rows), self.num_tags))\n",
    "        for i, question_id in enumerate(question_ids):\n",
    "            question_features[i,self.question_tags[question_id]] = 1\n",
    "\n",
    "        student_features = np.array([self.students[user_id].get_features(timestamp)\n",
    "                                     for user_id, timestamp in zip(user_ids, timestamps)])\n",
    "\n",
    "        return np.hstack([question_features, student_features])\n",
    "\n",
    "student_dataset = StudentDataset(lectures_df, questions_df, train_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 404153.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(train):\n",
    "    student_dataset.read(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.69565217],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.68888889],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.68181818],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.64102564],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.63157895],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.62162162]])"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example features with train\n",
    "student_dataset.get_features(train[0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}